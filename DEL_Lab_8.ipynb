{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqK1xBoqRjYH"
      },
      "outputs": [],
      "source": [
        "# Design a python program for Sentiment Analysis using Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('yelp.csv')\n",
        "data = data.sample(n=10000, random_state=42)\n",
        "reviews = data['text'].astype(str).tolist()\n",
        "labels = data['stars'].apply(lambda x: 1 if x >= 4 else 0).tolist()\n",
        "vocabsize = 10000\n",
        "maxlen = 200\n",
        "tokenizer = Tokenizer(num_words=vocabsize)\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "paddedseq = pad_sequences(sequences, maxlen=maxlen)\n",
        "paddedseq = np.array(paddedseq)\n",
        "labels = np.array(labels)\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(\n",
        "    paddedseq, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocabsize, output_dim=128, input_length=maxlen),\n",
        "    SimpleRNN(128, activation='tanh', return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(xtrain, ytrain,\n",
        "                    epochs=5,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(xtest, ytest))\n",
        "testloss, testaccuracy = model.evaluate(xtest, ytest)\n",
        "print(f\"Test Accuracy: {testaccuracy:.2f}\")\n",
        "samplereview = \"The food was great, and the service was excellent!\"\n",
        "encodedreview = tokenizer.texts_to_sequences([samplereview])\n",
        "paddedreview = pad_sequences(encodedreview, maxlen=maxlen)\n",
        "paddedreview = np.array(paddedreview)\n",
        "prediction = model.predict(paddedreview)\n",
        "sentiment = \"Positive\" if prediction[0] > 0.5 else \"Negative\"\n",
        "print(f\"\\nReview: {samplereview}\")\n",
        "print(f\"Predicted Sentiment: {sentiment}\")"
      ],
      "metadata": {
        "id": "9Mv9Za1PRqtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1950da4-f96f-4ef6-dfcd-9d2385aa93a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - accuracy: 0.6119 - loss: 0.6658 - val_accuracy: 0.6905 - val_loss: 0.6132\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 139ms/step - accuracy: 0.6691 - loss: 0.6388 - val_accuracy: 0.6905 - val_loss: 0.6189\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.6830 - loss: 0.6293 - val_accuracy: 0.6895 - val_loss: 0.6280\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - accuracy: 0.6795 - loss: 0.6307 - val_accuracy: 0.6905 - val_loss: 0.6229\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 133ms/step - accuracy: 0.6779 - loss: 0.6264 - val_accuracy: 0.7005 - val_loss: 0.5639\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6985 - loss: 0.5627\n",
            "Test Accuracy: 0.70\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\n",
            "Review: The food was great, and the service was excellent!\n",
            "Predicted Sentiment: Positive\n"
          ]
        }
      ]
    }
  ]
}